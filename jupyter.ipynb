{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Download dataset from GitHub\n",
        "url = 'https://raw.githubusercontent.com/dwyl/english-words/master/words.txt'\n",
        "response = requests.get(url)\n",
        "text = response.text.lower()\n",
        "\n",
        "# Prepare the dataset\n",
        "seq_length = 100\n",
        "sequences = []\n",
        "\n",
        "for i in range(seq_length, len(text)):\n",
        "    seq = text[i-seq_length:i]\n",
        "    sequences.append(seq)\n",
        "\n",
        "# Map characters to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {c: i for i, c in enumerate(chars)}\n",
        "int_to_char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# Create training data\n",
        "X = np.zeros((len(sequences), seq_length, len(chars)))\n",
        "y = np.zeros((len(sequences), len(chars)))\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_int[char]] = 1\n",
        "    y[i, char_to_int[text[i]]] = 1\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=20, batch_size=64)\n",
        "\n",
        "# Function to generate text\n",
        "def generate_lstm_text(seed_text, next_words=100):\n",
        "    result = seed_text\n",
        "    for _ in range(next_words):\n",
        "        # Encode the text to integers\n",
        "        encoded = np.zeros((1, seq_length, len(chars)))\n",
        "        for t, char in enumerate(seed_text[-seq_length:]):\n",
        "            encoded[0, t, char_to_int[char]] = 1\n",
        "        # Predict the next character\n",
        "        prediction = model.predict(encoded, verbose=0)\n",
        "        predicted_char_index = np.argmax(prediction)\n",
        "        predicted_char = int_to_char[predicted_char_index]\n",
        "        result += predicted_char\n",
        "        seed_text += predicted_char\n",
        "    return result\n",
        "\n",
        "# Example generation\n",
        "seed_text = \"Artificial intelligence is\"\n",
        "generated_text = generate_lstm_text(seed_text)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "ygpjiDDKJ0jI"
      },
      "id": "ygpjiDDKJ0jI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}